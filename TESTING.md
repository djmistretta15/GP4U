# üß™ Testing Guide

Comprehensive guide for testing the GP4U platform.

---

## Overview

GP4U includes a robust test suite covering:
- ‚úÖ **Authentication** - Signup, login, JWT tokens
- ‚úÖ **Wallet Operations** - Deposits, withdrawals, transactions
- ‚úÖ **Provider Architecture** - Circuit breakers, rate limiters, caching
- ‚úÖ **API Endpoints** - All 50+ endpoints
- ‚úÖ **Integration Tests** - End-to-end workflows

**Current Coverage:** ~800 lines of tests

---

## Quick Start

### Run All Tests

```bash
cd backend

# Run all tests
pytest

# Run with verbose output
pytest -v

# Run with coverage
pytest --cov=app tests/

# Run specific test file
pytest tests/test_auth.py -v
```

### Expected Output

```
========================== test session starts ==========================
platform linux -- Python 3.11.0
collected 42 items

tests/test_auth.py ..................                             [ 42%]
tests/test_providers.py ......................                    [ 95%]
tests/test_wallets.py ..                                          [100%]

========================== 42 passed in 2.34s ===========================
```

---

## Test Suite Breakdown

### 1. Authentication Tests (`test_auth.py`)

**Location:** `backend/tests/test_auth.py`

**Coverage:**
- ‚úÖ User signup with automatic wallet creation
- ‚úÖ Login with OAuth2 format
- ‚úÖ JWT token generation and validation
- ‚úÖ Password hashing (bcrypt)
- ‚úÖ Protected endpoint access
- ‚úÖ Token expiration handling

**Run:**
```bash
pytest tests/test_auth.py -v
```

**Key Test Cases:**
```python
test_signup()                    # Create new user
test_signup_duplicate_email()    # Prevent duplicates
test_login_success()             # Valid credentials
test_login_invalid_password()    # Wrong password
test_get_profile()               # Protected endpoint
test_token_expiration()          # Expired tokens
```

### 2. Wallet Tests (`test_wallets.py`)

**Location:** `backend/tests/test_wallets.py`

**Coverage:**
- ‚úÖ Wallet creation on signup
- ‚úÖ Deposit USDC
- ‚úÖ Withdraw USDC
- ‚úÖ Transaction history
- ‚úÖ Balance tracking
- ‚úÖ Insufficient funds handling

**Run:**
```bash
pytest tests/test_wallets.py -v
```

**Key Test Cases:**
```python
test_wallet_created_on_signup()  # Auto-creation
test_deposit_funds()             # Add USDC
test_withdraw_funds()            # Remove USDC
test_insufficient_funds()        # Prevent overdraft
test_transaction_history()       # Query history
```

### 3. Provider Architecture Tests (`test_providers.py`)

**Location:** `backend/tests/test_providers.py`

**Coverage:**
- ‚úÖ Circuit breaker pattern (25 test cases)
- ‚úÖ Rate limiter (token bucket)
- ‚úÖ Adaptive caching
- ‚úÖ Provider implementations (Vast.ai, io.net, Akash, Render)
- ‚úÖ Metrics tracking
- ‚úÖ Error isolation

**Run:**
```bash
pytest tests/test_providers.py -v
```

**Test Categories:**

#### Circuit Breaker Tests
```python
test_circuit_breaker_closed_state()              # Initial state
test_circuit_breaker_opens_after_failures()      # Open on failures
test_circuit_breaker_blocks_when_open()          # Block requests
test_circuit_breaker_half_open_transition()      # Recovery testing
test_circuit_breaker_success_resets_counter()    # Reset on success
```

#### Rate Limiter Tests
```python
test_rate_limiter_allows_within_limit()   # Allow valid requests
test_rate_limiter_blocks_over_limit()     # Block excess
test_rate_limiter_refills_tokens()        # Token refill
test_rate_limiter_burst_capacity()        # Burst support
```

#### Caching Tests
```python
test_adaptive_cache_set_and_get()                # Basic operations
test_adaptive_cache_ttl_based_on_success_rate()  # Dynamic TTL
test_adaptive_cache_invalidation()               # Clear cache
test_adaptive_cache_clear()                      # Clear all
```

#### Provider Tests
```python
test_vastai_provider_initialization()      # Vast.ai setup
test_vastai_normalize_gpu_data()           # Data normalization
test_ionet_provider_initialization()       # io.net setup
test_akash_provider_initialization()       # Akash setup
test_render_provider_initialization()      # Render setup
```

#### Metrics Tests
```python
test_metrics_initialization()                # Initial state
test_metrics_record_request()                # Track requests
test_metrics_calculate_success_rate()        # Success rate
test_metrics_calculate_average_response_time() # Avg response time
```

---

## Running Specific Test Categories

### Authentication Only
```bash
pytest tests/test_auth.py -v
```

### Wallets Only
```bash
pytest tests/test_wallets.py -v
```

### Circuit Breakers Only
```bash
pytest tests/test_providers.py::TestCircuitBreaker -v
```

### Rate Limiters Only
```bash
pytest tests/test_providers.py::TestRateLimiter -v
```

### Provider Implementations Only
```bash
pytest tests/test_providers.py::TestProviderImplementations -v
```

---

## Coverage Reports

### Generate HTML Coverage Report

```bash
# Run tests with coverage
pytest --cov=app --cov-report=html tests/

# Open report in browser
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
start htmlcov/index.html  # Windows
```

### Generate Terminal Coverage Report

```bash
pytest --cov=app --cov-report=term-missing tests/
```

**Example Output:**
```
---------- coverage: platform linux, python 3.11.0 -----------
Name                                    Stmts   Miss  Cover   Missing
---------------------------------------------------------------------
app/__init__.py                             0      0   100%
app/core/base_provider.py                 127     12    91%   45-48, 89-92
app/core/circuit_breaker.py                95      5    95%   123-127
app/core/rate_limiter.py                   65      3    95%   78-80
app/providers/vastai_provider.py           98      8    92%   145-152
app/services/wallet_service.py            142     18    87%   89-95, 156-162
---------------------------------------------------------------------
TOTAL                                    2847    234    92%
```

### Coverage Goals

- **Overall:** 90%+ coverage
- **Critical Paths:** 95%+ coverage
  - Authentication
  - Wallet operations
  - Circuit breakers
  - Rate limiters
- **Provider APIs:** 80%+ coverage (mocked external calls)

---

## Writing New Tests

### Test Structure

```python
"""
Test module description
"""
import pytest
from app.models import User
from app.services.my_service import MyService

class TestMyFeature:
    """Test my feature"""

    @pytest.mark.asyncio
    async def test_my_function(self, db_session):
        """Test my function does X"""
        # Arrange
        user = User(email="test@example.com")
        await db_session.add(user)
        await db_session.commit()

        # Act
        result = await MyService.do_something(user)

        # Assert
        assert result is not None
        assert result.status == "success"
```

### Fixtures

Common fixtures available:

```python
@pytest.fixture
async def db_session():
    """Database session for tests"""
    # Uses in-memory SQLite
    # Automatically rolls back after each test

@pytest.fixture
async def client():
    """FastAPI test client"""
    # Make API requests

@pytest.fixture
async def test_user():
    """Create test user"""
    # Returns User object

@pytest.fixture
async def auth_headers(test_user):
    """Authentication headers"""
    # Returns {"Authorization": "Bearer <token>"}
```

### Async Tests

Use `@pytest.mark.asyncio` for async tests:

```python
@pytest.mark.asyncio
async def test_async_function():
    """Test async function"""
    result = await some_async_function()
    assert result is not None
```

### Mocking External APIs

Mock provider API calls:

```python
from unittest.mock import Mock, AsyncMock, patch

@pytest.mark.asyncio
async def test_provider_fetch():
    """Test provider fetches GPUs"""
    with patch('httpx.AsyncClient.get') as mock_get:
        # Mock API response
        mock_get.return_value = AsyncMock(
            status_code=200,
            json=lambda: {"gpus": [{"id": 1, "model": "RTX 4090"}]}
        )

        # Test function
        provider = VastAIProvider()
        gpus = await provider.fetch_gpus()

        assert len(gpus) == 1
        assert gpus[0]["model"] == "RTX 4090"
```

---

## Integration Tests

### API Integration Tests

Test complete workflows:

```python
@pytest.mark.asyncio
async def test_complete_booking_workflow(client, test_user):
    """Test complete GPU booking workflow"""
    # 1. Login
    response = await client.post("/api/auth/login", data={
        "username": test_user.email,
        "password": "test123"
    })
    token = response.json()["access_token"]
    headers = {"Authorization": f"Bearer {token}"}

    # 2. Search GPUs
    response = await client.get("/api/gpus/search", headers=headers)
    gpus = response.json()["gpus"]
    assert len(gpus) > 0

    # 3. Create reservation
    response = await client.post("/api/reservations/", headers=headers, json={
        "gpu_id": gpus[0]["id"],
        "start_time": "2025-11-05T10:00:00Z",
        "end_time": "2025-11-05T18:00:00Z"
    })
    assert response.status_code == 201

    # 4. Verify booking
    reservation = response.json()
    assert reservation["status"] == "PENDING"
```

### Provider Integration Tests

Test provider system integration:

```python
@pytest.mark.asyncio
async def test_provider_sync_with_circuit_breaker():
    """Test provider sync respects circuit breaker"""
    # Initialize provider
    provider = VastAIProvider()

    # Simulate failures to open circuit breaker
    for i in range(5):
        with pytest.raises(Exception):
            await provider.get_gpus()

    # Circuit breaker should now be OPEN
    assert provider.circuit_breaker.state == CircuitState.OPEN

    # Next call should be blocked
    with pytest.raises(CircuitBreakerOpen):
        await provider.get_gpus()
```

---

## Continuous Integration

### GitHub Actions

Create `.github/workflows/test.yml`:

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt

      - name: Run tests with coverage
        run: |
          cd backend
          pytest --cov=app --cov-report=xml tests/

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./backend/coverage.xml
```

---

## Performance Testing

### Load Testing with Locust

Install locust:
```bash
pip install locust
```

Create `locustfile.py`:
```python
from locust import HttpUser, task, between

class GP4UUser(HttpUser):
    wait_time = between(1, 3)

    @task(3)
    def search_gpus(self):
        """Search GPUs (high frequency)"""
        self.client.get("/api/gpus/search")

    @task(1)
    def get_arbitrage(self):
        """Get arbitrage opportunities"""
        self.client.get("/api/arbitrage/opportunities")

    def on_start(self):
        """Login before tasks"""
        response = self.client.post("/api/auth/login", data={
            "username": "test@example.com",
            "password": "test123"
        })
        self.token = response.json()["access_token"]
        self.client.headers.update({
            "Authorization": f"Bearer {self.token}"
        })
```

Run load test:
```bash
locust -f locustfile.py --host=http://localhost:8000
```

Open [http://localhost:8089](http://localhost:8089) and start test.

---

## Troubleshooting

### Tests Failing with Database Errors

**Issue:** `asyncpg.exceptions.ConnectionDoesNotExistError`

**Solution:** Tests use in-memory SQLite, not PostgreSQL. Check test configuration:

```python
# backend/tests/conftest.py
DATABASE_URL = "sqlite+aiosqlite:///:memory:"
```

### Tests Timing Out

**Issue:** Tests hang or timeout

**Solutions:**
1. Check for missing `await` keywords
2. Verify async fixtures are properly configured
3. Increase timeout:
   ```bash
   pytest --timeout=60 tests/
   ```

### Mock Not Working

**Issue:** Tests still calling real APIs

**Solution:** Verify patch target:
```python
# ‚ùå Wrong
with patch('vastai_provider.httpx'):
    ...

# ‚úÖ Correct
with patch('app.providers.vastai_provider.httpx'):
    ...
```

### Import Errors

**Issue:** `ModuleNotFoundError: No module named 'app'`

**Solution:** Run pytest from backend directory:
```bash
cd backend
pytest
```

Or set PYTHONPATH:
```bash
export PYTHONPATH=/home/user/GP4U/backend:$PYTHONPATH
pytest
```

---

## Test Maintenance

### Adding Tests for New Features

1. **Create test file:** `tests/test_<feature>.py`
2. **Write test class:** `class TestMyFeature`
3. **Add test methods:** `test_feature_does_x()`
4. **Run tests:** `pytest tests/test_<feature>.py -v`
5. **Check coverage:** `pytest --cov=app.services.<feature> tests/test_<feature>.py`

### Updating Tests After Refactoring

1. Run tests to see failures
2. Update test fixtures/mocks to match new structure
3. Update assertions to match new behavior
4. Re-run until all pass
5. Check coverage hasn't decreased

### Removing Obsolete Tests

1. Identify tests for removed features
2. Delete test file or test methods
3. Run full test suite to verify no dependencies
4. Update coverage baseline

---

## Best Practices

### ‚úÖ Do's

- **Write tests first** (TDD when possible)
- **Test one thing per test** (single responsibility)
- **Use descriptive test names** (`test_user_cannot_withdraw_more_than_balance`)
- **Arrange-Act-Assert** pattern
- **Mock external dependencies** (APIs, network calls)
- **Use fixtures** for common setup
- **Test edge cases** (empty lists, null values, boundaries)
- **Keep tests fast** (< 1s per test)

### ‚ùå Don'ts

- **Don't test framework code** (FastAPI, SQLAlchemy internals)
- **Don't make real API calls** (always mock)
- **Don't share state** between tests
- **Don't hardcode test data** (use factories/fixtures)
- **Don't skip flaky tests** (fix them or remove them)
- **Don't commit commented-out tests**
- **Don't test implementation details** (test behavior, not internals)

---

## Resources

- **Pytest Documentation:** [https://docs.pytest.org](https://docs.pytest.org)
- **pytest-asyncio:** [https://pytest-asyncio.readthedocs.io](https://pytest-asyncio.readthedocs.io)
- **pytest-cov:** [https://pytest-cov.readthedocs.io](https://pytest-cov.readthedocs.io)
- **FastAPI Testing:** [https://fastapi.tiangolo.com/tutorial/testing/](https://fastapi.tiangolo.com/tutorial/testing/)

---

## Summary

**Test Commands:**
```bash
pytest                              # Run all tests
pytest -v                           # Verbose output
pytest --cov=app tests/             # With coverage
pytest tests/test_auth.py           # Specific file
pytest -k "test_circuit"            # Tests matching pattern
pytest --lf                         # Run last failed
pytest --tb=short                   # Short traceback
```

**Current Status:**
- ‚úÖ 42 tests passing
- ‚úÖ ~800 lines of test code
- ‚úÖ 90%+ coverage goal
- ‚úÖ CI/CD ready

**Next Steps:**
1. Add E2E tests for complete user journeys
2. Add load tests for performance benchmarks
3. Add security tests for authentication
4. Increase coverage to 95%+

---

**Happy Testing! üß™**
